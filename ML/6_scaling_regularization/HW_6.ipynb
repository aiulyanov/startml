{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71833815",
   "metadata": {},
   "source": [
    "### Замерим качество Линейной регрессии после обработки данных не просто на отложенной выборке, но и на Кросс-Валидации на 4 фолдах!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4355dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb298541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458644, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = pd.read_csv('processed_data.csv', index_col='id')\n",
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5debb58c",
   "metadata": {},
   "source": [
    "#### ! Не перемешивайте данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8678af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = KFold(n_splits=4)\n",
    "\n",
    "### Шаг №5\n",
    "### Замерьте качество (MSLE, как и раньше) на Кросс-валидации, \n",
    "### используя MSE от log_trip_duration и назначенный selector\n",
    "\n",
    "### Your code is here\n",
    "X = processed_data.drop('log_trip_duration', axis=1)\n",
    "y = processed_data['log_trip_duration']\n",
    "losses = []\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "\n",
    "for train_idx, test_idx in selector.split(X, y):\n",
    "    X_fold_train, X_fold_test = X.values[train_idx], X.values[test_idx]\n",
    "    y_fold_train, y_fold_test = y.values[train_idx], y.values[test_idx]\n",
    "\n",
    "    model_1.fit(X_fold_train, y_fold_train)\n",
    "    y_fold_pred = model_1.predict(X_fold_test)\n",
    "\n",
    "    metric = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    losses.append(metric)\n",
    "cross_val_error = np.mean(losses)\n",
    "\n",
    "print(f\"MSLE на Кросс-валидации: {round(cross_val_error, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586759d",
   "metadata": {},
   "source": [
    "## Поработал один из хитрых гномов!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a763e",
   "metadata": {},
   "source": [
    "В отличие от своих собратьев, третий гном оказался тем еще бездельником в школьные годы, но все равно страстно желал во всем догнать первых двух. И сейчас, желая помочь им в построении модели по предсказанию длительности поездки такси, добавил в данные 20 зашифрованных фичей (их смысл нам не рассказали: какая-то секретная информация о водителях).\n",
    "\n",
    "Гном думал следующим образом: \"Ну не может же модель стать хуже! А тут вот авось и мое нововведение уменьшит ошибку в разы! Тогда и меня станут звать на гномий  data-саммит.\"\n",
    "\n",
    "Проверим на кросс-валидации, насколько гном оказался прав!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538a0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('new_data.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c5dd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458644, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Шаг №6\n",
    "### Замерьте качество (MSLE, как и раньше) на Кросс-валидации, \n",
    "### используя MSE от log_trip_duration и назначенный ранее selector\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# selector = KFold(n_splits=4)\n",
    "# X = new_data.drop('log_trip_duration', axis=1)\n",
    "# y = new_data['log_trip_duration']\n",
    "# losses = []\n",
    "\n",
    "# model_1 = LinearRegression()\n",
    "\n",
    "# for train_idx, test_idx in selector.split(X, y):\n",
    "#     X_fold_train, X_fold_test = X.values[train_idx], X.values[test_idx]\n",
    "#     y_fold_train, y_fold_test = y.values[train_idx], y.values[test_idx]\n",
    "\n",
    "#     model_1.fit(X_fold_train, y_fold_train)\n",
    "#     y_fold_pred = model_1.predict(X_fold_test)\n",
    "\n",
    "#     metric = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "#     losses.append(metric)\n",
    "# cross_val_error_2 = np.mean(losses)\n",
    "\n",
    "# print(f\"MSLE: {round(cross_val_error_2, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "X_new = new_data.drop('log_trip_duration', axis=1)\n",
    "y_new = new_data['log_trip_duration']\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "\n",
    "# Define a custom scorer for mean squared error\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform cross-validation and calculate the negative MSE\n",
    "cross_val_scores = cross_val_score(model_2, X_new, y_new, cv=4, scoring=mse_scorer)\n",
    "\n",
    "# Calculate the mean of the negative MSE scores\n",
    "cross_val_error_2 = -cross_val_scores.mean()\n",
    "\n",
    "print(f\"MSLE: {round(cross_val_error_2, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f2945",
   "metadata": {},
   "source": [
    "В линейной алгербре зачастую используют понятие **ранга матрицы**. Оно соответствует кол-ву линейно независимых столбцов в матрице. Иными словами, позволяет оценить, есть ли избыток информации в нашем датафрейме. Если ранг матрицы меньше, чем кол-во используемых столбцов, то некоторые фичи следует удалить, ведь иначе возникает ситуация строгой мультиколлинеарности.\n",
    "\n",
    "Чтобы замерить ранг в наших матрицах объект-признак, можно воспользоваться функцией numpy.linalg.matrix_rank\n",
    "\n",
    "Константным признаком в данном упражнении можно пренебречь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Создайте переменные rank_processed, rank_new \n",
    "### Соответственно равные рангу изначальной матрицы\n",
    "### с данными и рангу матрицы третьего гнома\n",
    "\n",
    "### Your code is here\n",
    "rank_processed = np.linalg.matrix_rank(processed_data.drop('log_trip_duration', axis=1))\n",
    "rank_new = np.linalg.matrix_rank(new_data.drop('log_trip_duration', axis=1))\n",
    "print(rank_processed, rank_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Создайте переменные num_features_processed, num_features_new\n",
    "### Соответственно равные кол-ву фичей в изначальной матрицы\n",
    "### с данными и кол-ву фичей у третьего гнома\n",
    "\n",
    "### Your code is here\n",
    "num_features_processed = processed_data.drop('log_trip_duration', axis=1).shape[1]\n",
    "num_features_new = new_data.drop('log_trip_duration', axis=1).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Шаг №7\n",
    "print(f\"В первой модели всего фичей: {num_features_processed}, - а ранг равен {rank_processed}\")\n",
    "\n",
    "print(f\"Во второй модели всего фичей: {num_features_new}, - а ранг равен {rank_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194b8ab",
   "metadata": {},
   "source": [
    "Не кажется ли нам, что из-за новых 20 фичей появилась проблема мультиколлинеарности? Как поступить гному, чтобы, с одной стороны, получить адекватное качество, а с другой стороны, не повредить свое самолюбие и не убирать новые признаки?\n",
    "\n",
    "Верно! Например, с помощью регуляризации.\n",
    "\n",
    "Найдите такой параметр регуляризации $\\alpha$ для Ridge и Lasso случая, чтобы ошибка MSLE на кросс-валидации оказалась строго меньше 0.4\n",
    "\n",
    "**ALARM**: используйте процедуру масштабирования данных (воспользуйтесь методом MinMaxScaler) перед тем как применить регуляризацию. Важно - чтобы сохранить концепцию независимости обучения на трейне и на тесте, на каждой итерации кросс-валидации необходимо замерять параметры стандартизации исключительно на трейне, а потом применять на валидационном фолде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Пример, как это можно сделать в цикле\n",
    "### То есть обучить Lasso, учитывая масштабирование\n",
    "### Исключительно на трейне на каждой итерации\n",
    "\n",
    "\n",
    "\n",
    "X = new_data.drop('log_trip_duration', axis=1)\n",
    "Y = new_data['log_trip_duration']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in selector.split(X):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    Y_train, Y_test = Y.values[train_index], Y.values[test_index]\n",
    "    \n",
    "    ### Фитим исключительно на трейне!\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    ### Применяем обученный scaler на трейн и тест\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    ### max_iter иногда требуется ставить побольше, \n",
    "    ### особенно когда данных много и/или они сложные\n",
    "    ### этот параметр регулирует верхнюю границу кол-ва\n",
    "    ### итераций во время обучения\n",
    "    ### подробнее - в документации\n",
    "    \n",
    "    ### По дефолту здесь параметр регуляризации alpha=1\n",
    "    \n",
    "    model_lasso = Lasso(max_iter=100000) \n",
    "    model_lasso.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    predictions = model_lasso.predict(X_test_scaled)\n",
    "    \n",
    "    scores.append(np.mean((predictions - Y_test)**2))\n",
    "\n",
    "    \n",
    "print(f\"MSLE на Кросс-валидации равен: {np.mean(scores)}\")\n",
    "\n",
    "### P.S. если вы уже умеете работать с конструкциями\n",
    "### Pipeline, GridSearchCV, cross_validate\n",
    "### Можете использовать их. Мы познакомимся с ними позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Теперь найдите оптимальный параметр регуляризации\n",
    "### для случая Ridge\n",
    "### Напомним: ошибка на кросс-валидации должно быть \n",
    "### строго меньше 0.4\n",
    "\n",
    "### Шаг №8\n",
    "### Your code is here\n",
    "X = new_data.drop('log_trip_duration', axis=1)\n",
    "Y = new_data['log_trip_duration']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in selector.split(X):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    Y_train, Y_test = Y.values[train_index], Y.values[test_index]\n",
    "    \n",
    "    ### Фитим исключительно на трейне!\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    ### Применяем обученный scaler на трейн и тест\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    ### max_iter иногда требуется ставить побольше, \n",
    "    ### особенно когда данных много и/или они сложные\n",
    "    ### этот параметр регулирует верхнюю границу кол-ва\n",
    "    ### итераций во время обучения\n",
    "    ### подробнее - в документации\n",
    "    \n",
    "    ### По дефолту здесь параметр регуляризации alpha=1\n",
    "    \n",
    "    model_lasso = Ridge(max_iter=100000, alpha=0.12) \n",
    "    model_lasso.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    predictions = model_lasso.predict(X_test_scaled)\n",
    "    \n",
    "    scores.append(np.mean((predictions - Y_test)**2))\n",
    "\n",
    "    \n",
    "print(f\"MSLE на Кросс-валидации равен: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c384465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE на Кросс-валидации равен: 0.3984816859563738\n"
     ]
    }
   ],
   "source": [
    "### Найдите оптимальный параметр регуляризации\n",
    "### для случая Lasso\n",
    "### Напомним: ошибка на кросс-валидации должно быть \n",
    "### строго меньше 0.4\n",
    "\n",
    "### Шаг №9\n",
    "### Your code is here\n",
    "\n",
    "X = new_data.drop('log_trip_duration', axis=1)\n",
    "Y = new_data['log_trip_duration']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "scores = []\n",
    "selector = KFold(n_splits=4)\n",
    "\n",
    "for train_index, test_index in selector.split(X):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    Y_train, Y_test = Y.values[train_index], Y.values[test_index]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model_lasso = Lasso(max_iter=100000, alpha=0.00001) \n",
    "\n",
    "    model_lasso.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    predictions = model_lasso.predict(X_test_scaled)\n",
    "    \n",
    "    scores.append(np.mean((predictions - Y_test)**2))\n",
    "\n",
    "    \n",
    "print(f\"MSLE на Кросс-валидации равен: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6701650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47021966223477824,\n",
       " 0.5069334082998875,\n",
       " 0.5087189035231492,\n",
       " 0.5081503244152612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
